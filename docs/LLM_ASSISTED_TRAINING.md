# Treinamento Assistido por LLM (Fluxo PDF-First)

> üí° **Contexto**: o assistente LLM agora est√° embutido no PDF Training Wizard. Este documento descreve como habilitar o painel na UI, quais vari√°veis de ambiente controlar e como automatizar o processo via API. Ao final h√° um ap√™ndice sobre o fluxo legado baseado em CSV para refer√™ncia hist√≥rica.

## Vis√£o geral do painel

1. **Upload e pr√©-processamento** ‚Äì ap√≥s enviar o PDF pelo wizard, o backend cria a anota√ß√£o inicial e registra as entidades detectadas.
2. **Gera√ß√£o de sugest√µes** ‚Äì no painel lateral ‚ÄúLLM Helper‚Äù, clique em **Generate suggestions**. Um job ass√≠ncrono (`JobType.support_llm`) √© criado para coletar contexto, montar o prompt e chamar o modelo configurado.
3. **Revis√£o humana** ‚Äì as sugest√µes s√£o exibidas em uma tabela com campo, valor proposto, confian√ßa e observa√ß√µes. Use os bot√µes de aceitar/rejeitar por linha; apenas as decis√µes aprovadas s√£o persistidas.
4. **Datasets atualizados** ‚Äì ao concluir a revis√£o, gere um treinamento ou exporte datasets diretamente pela UI. Os artefatos (`supervised.jsonl`, `st_pairs.jsonl`, modelos) refletem as corre√ß√µes aplicadas.

> ‚úÖ **Boas pr√°ticas**
> - Execute o helper apenas depois do pr√©-processamento terminar (status `SUCCEEDED`).
> - Trabalhe com lotes menores de documentos para facilitar auditoria.
> - Revise os custos estimados exibidos no painel antes de habilitar chamadas reais.

## Vari√°veis de ambiente

| Vari√°vel | Default | Descri√ß√£o |
| --- | --- | --- |
| `PDF_TRAINING_LLM_PROVIDER` | `deepseek` | Provedor suportado (`deepseek`, `openai`, etc.). |
| `PDF_TRAINING_LLM_MODEL` | `deepseek-chat` | Modelo solicitado ao provedor. |
| `PDF_TRAINING_LLM_DRY_RUN` | `true` | Quando `true`, gera respostas simuladas (sem chamadas externas). |
| `PDF_TRAINING_LLM_FIELDS` | ‚Äì | Lista separada por v√≠rgulas com os campos que devem receber sugest√µes. |
| `PDF_TRAINING_LLM_TEMPERATURE` | `0.0` | Temperatura usada na chamada oficial ao provedor. |
| `PDF_TRAINING_LLM_TOP_P` | `0.9` | Par√¢metro de amostragem complementar √† temperatura. |
| `PDF_TRAINING_LLM_TIMEOUT` | `30.0` | Timeout (segundos) para chamadas reais. |
| `PDF_TRAINING_LLM_API_KEY` | ‚Äì | Chave expl√≠cita do provedor; se ausente, o helper tenta `DEEPSEEK_API_KEY` ou `OPENAI_API_KEY`. |

Para ambientes de QA, mantenha `PDF_TRAINING_LLM_DRY_RUN=true` e ajuste `PDF_TRAINING_LLM_FIELDS` para focar em poucos campos. Em produ√ß√£o, configure a chave correspondente e monitore o painel de custos.

## Automa√ß√£o via API

O frontend utiliza endpoints dedicados. Eles podem ser consumidos por integra√ß√µes externas:

- **Disparar sugest√µes**
  ```bash
  curl -X POST \
    "http://localhost:8008/api/pdf-training/documents/<document_id>/support/llm" \
    -H "Content-Type: application/json" \
    -d '{"fields": ["supplier_name", "contract_type"], "provider": "deepseek"}'
  ```
- **Consultar resultado**
  ```bash
  curl "http://localhost:8008/api/pdf-training/documents/<document_id>/support/llm"
  ```
- **Acompanhar o job**
  ```bash
  curl "http://localhost:8008/api/pdf-training/jobs?resource_type=document&resource_id=<document_id>"
  ```

Os payloads retornam a decis√£o do modelo (`decision`), justificativas (`rationale`), custos estimados (`estimated_cost`) e os valores propostos. Combine com o endpoint `/documents/{id}/entities` para exibir os dados atuais lado a lado.

## Perguntas frequentes

**Posso salvar automaticamente as sugest√µes?**
: N√£o. Mesmo no fluxo API o helper apenas escreve recomenda√ß√µes. A aprova√ß√£o final continua manual na UI para preservar o controle HITL.

**Como for√ßar uma execu√ß√£o s√≠ncrona em testes?**
: Defina `PDF_TRAINING_FORCE_SYNC_JOBS=true`. Os jobs de suporte passam a rodar no mesmo processo, facilitando asserts em pytest.

**√â poss√≠vel usar outro provedor?**
: Sim. Desde que exista suporte no m√≥dulo `tools.llm_critique`, basta setar `PDF_TRAINING_LLM_PROVIDER`/`MODEL` e fornecer a chave via vari√°vel de ambiente correspondente.

## Ap√™ndice A ‚Äî Fluxo legado baseado em CSV

> ‚ö†Ô∏è **Descontinuado**: as instru√ß√µes abaixo descrevem o antigo pipeline `review.csv` + `feedback_cli`. Use apenas para consultar hist√≥ricos ou reproduzir experimentos antigos.

1. Gerar cr√≠ticas com `tools/llm_critique.py`, produzindo colunas `_llm_suggested` em uma c√≥pia do CSV.
2. Opcionalmente criar pares sint√©ticos com `tools/self_augment.py`.
3. Executar o modo gamificado de `feedback_cli.py train-st` para aceitar/rejeitar sugest√µes e regenerar datasets.

O arquivo `tools/feedback_cli.py` atual apenas imprime uma mensagem informando que o fluxo foi removido. Para qualquer implementa√ß√£o nova, baseie-se na UI ou nos endpoints documentados neste guia.
