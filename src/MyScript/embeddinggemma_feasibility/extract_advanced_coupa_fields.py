"""
Advanced Coupa Field Extractor - Quick Start
Script simplificado para extra√ß√£o avan√ßada com m√∫ltiplas bibliotecas NLP
"""

import os
import sys
from pathlib import aePath

# Adicionar o diret√≥rio atual ao path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from advanced_coupa_field_extractor import AdvancedCoupaPDFFieldExtractor


def main():
    """Fun√ß√£o principal simplificada para extra√ß√£o avan√ßada."""
    print("üìÑ Extrator Avan√ßado de Campos do Coupa com NLP")
    print("=" * 60)
    
    # Diret√≥rio dos PDFs
    pdf_directory = "/Users/juliocezar/Dev/work/CoupaDownloads/src/data/P2"
    
    print(f"üìÅ Diret√≥rio dos PDFs: {pdf_directory}")
    
    # Verificar se o diret√≥rio existe
    if not os.path.exists(pdf_directory):
        print(f"‚ùå Diret√≥rio n√£o encontrado: {pdf_directory}")
        print("üí° Certifique-se de que a pasta P2 existe e cont√©m arquivos PDF")
        return
    
    # Criar extrator avan√ßado
    print("üîß Inicializando extrator avan√ßado com m√∫ltiplas bibliotecas NLP...")
    extractor = AdvancedCoupaPDFFieldExtractor(pdf_directory)
    
    # Verificar bibliotecas dispon√≠veis
    print(f"üìö Bibliotecas NLP dispon√≠veis: {', '.join(extractor.available_libraries)}")
    
    if not extractor.available_libraries:
        print("‚ö†Ô∏è Nenhuma biblioteca NLP dispon√≠vel!")
        print("üí° Instale pelo menos uma das seguintes:")
        print("   - spaCy: pip install spacy && python -m spacy download pt_core_news_sm")
        print("   - Transformers: pip install transformers")
        print("   - Sentence Transformers: pip install sentence-transformers")
        print("   - LangChain: pip install langchain")
        print("   - Ollama: pip install ollama")
        return
    
    # Verificar se h√° PDFs
    pdf_files = extractor.find_pdf_files()
    if not pdf_files:
        print("‚ö†Ô∏è Nenhum arquivo PDF encontrado na pasta P2")
        print("üí° Adicione alguns arquivos PDF na pasta para testar")
        return
    
    print(f"üìÑ Encontrados {len(pdf_files)} arquivos PDF")
    
    # Processar PDFs
    print("\nüöÄ Iniciando extra√ß√£o avan√ßada com m√∫ltiplas t√©cnicas NLP...")
    extractions = extractor.process_all_pdfs()
    
    if extractions:
        print(f"\n‚úÖ Processamento conclu√≠do com sucesso!")
        print(f"üìä Documentos processados: {len(extractions)}")
        
        # Calcular estat√≠sticas
        avg_confidence = sum(e.extraction_confidence for e in extractions) / len(extractions)
        print(f"üìà Confian√ßa m√©dia da extra√ß√£o: {avg_confidence:.2f}")
        
        # Salvar CSV
        csv_file = extractor.save_to_csv(extractions)
        print(f"üíæ CSV salvo em: {csv_file}")
        
        # Gerar relat√≥rio
        report = extractor.generate_extraction_report(extractions)
        report_file = csv_file.replace('.csv', '_report.md')
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"üìã Relat√≥rio salvo em: {report_file}")
        
        # Mostrar campos mais encontrados
        field_counts = {}
        for field_name in extractor.target_fields:
            count = sum(1 for e in extractions if getattr(e, field_name, "").strip())
            field_counts[field_name] = count
        
        print(f"\nüîç Campos mais encontrados:")
        sorted_fields = sorted(field_counts.items(), key=lambda x: x[1], reverse=True)
        for field_name, count in sorted_fields[:10]:
            if count > 0:
                field_display = field_name.replace('_', ' ').title()
                print(f"  - {field_display}: {count} documentos")
        
        # Mostrar estat√≠sticas por biblioteca NLP
        library_stats = {}
        for extraction in extractions:
            for lib in extraction.nlp_libraries_used or []:
                if lib not in library_stats:
                    library_stats[lib] = 0
                library_stats[lib] += 1
        
        print(f"\nüìö Uso das bibliotecas NLP:")
        for lib, count in library_stats.items():
            print(f"  - {lib}: {count} documentos")
        
        # Mostrar exemplos de campos extra√≠dos
        print(f"\nüìã Exemplos de campos extra√≠dos:")
        for i, extraction in enumerate(extractions[:3], 1):  # Mostrar apenas os primeiros 3
            print(f"\n{i}. {extraction.source_file}")
            print(f"   Confian√ßa: {extraction.extraction_confidence:.2f}")
            print(f"   Bibliotecas: {', '.join(extraction.nlp_libraries_used or [])}")
            
            # Mostrar alguns campos encontrados
            fields_shown = 0
            for field_name in extractor.target_fields:
                field_value = getattr(extraction, field_name, "")
                if field_value and field_value.strip() and fields_shown < 3:
                    field_display = field_name.replace('_', ' ').title()
                    print(f"   {field_display}: {field_value}")
                    fields_shown += 1
            
            if fields_shown == 0:
                print("   Nenhum campo espec√≠fico encontrado")
        
        print(f"\nüìä Resumo da extra√ß√£o avan√ßada:")
        print(f"   Total de campos dispon√≠veis: {len(extractor.target_fields)}")
        print(f"   Documentos com pelo menos 1 campo: {sum(1 for e in extractions if e.extraction_confidence > 0)}")
        print(f"   Documentos com alta confian√ßa (>0.5): {sum(1 for e in extractions if e.extraction_confidence > 0.5)}")
        print(f"   Bibliotecas NLP utilizadas: {len(extractor.available_libraries)}")
        
    else:
        print(f"\n‚ùå Nenhum documento processado com sucesso")
        print("üí° Verifique se os PDFs cont√™m texto leg√≠vel e se as bibliotecas NLP est√£o funcionando")


if __name__ == "__main__":
    main()
